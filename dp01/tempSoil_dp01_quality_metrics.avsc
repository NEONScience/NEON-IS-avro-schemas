{
  "type": "record",
  "name": "tempSoil_dp01_quality_metrics",
  "namespace": "org.neonscience.schema.dp01",
  "doc": "L1 quality metrics and final quality flag for soil temperature",
  "fields": [
    {
      "name": "startDateTime",
      "type": {
        "type": "long",
        "logicalType": "timestamp-millis"
      },
      "doc": "Date and time at which a sampling is initiated (inclusive)"
    },
    {
      "name": "endDateTime",
      "type": {
        "type": "long",
        "logicalType": "timestamp-millis"
      },
      "doc": "Date and time at which a sampling is completed (exclusive)"
    },
    {
      "name": "nullPassQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the passed outcomes of the null test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "nullFailQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the failed outcomes of the null test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "nullNAQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes when the null test could not be run over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "gapPassQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the passed outcomes of the gap test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "gapFailQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the failed outcomes of the gap test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "gapNAQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes when the gap test could not be run over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "rangePassQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the passed outcomes of the range test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "rangeFailQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the failed outcomes of the range test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "rangeNAQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes when the range test could not be run over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "stepPassQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the passed outcomes of the step test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "stepFailQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the failed outcomes of the step test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "stepNAQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes when the step test could not be run over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "spikePassQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the passed outcomes of the spike test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "spikeFailQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the failed outcomes of the spike test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "spikeNAQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes when the spike test could not be run over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "persistencePassQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the passed outcomes of the persistence test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "persistenceFailQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the failed outcomes of the persistence test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "persistenceNAQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes when the persistence test could not be run over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "validCalPassQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the passed outcomes of the valid calibration test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "validCalFailQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the failed outcomes of the valid calibration test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "validCalNAQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes when the valid calibration test could not be run over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "suspectCalPassQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the passed outcomes of the suspect calibration test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "suspectCalFailQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes the failed outcomes of the suspect calibration test over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "suspectCalNAQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric that summarizes when the suspect calibration test could not be run over the averaging period, as a percent",
      "__neon_units": "percent"
    },
    {
      "name": "alphaQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric detailing the outcomes of the alpha quality flag over the averaging period, as a percent and detailed in NEON.DOC.001113",
      "__neon_units": "percent"
    },
    {
      "name": "betaQM",
      "type": [
        "null",
        "float"
        ],
      "default": null,
      "doc": "Quality metric detailing the outcomes of the beta quality flag over the averaging period, as a percent and detailed in NEON.DOC.001113",
      "__neon_units": "percent"
    },
    {
      "name": "finalQF",
      "type": [
        "null",
        "int"
        ],
      "default": null,
      "doc": "Quality flag indicating whether a data product has passed or failed an overall assessment of its quality, detailed in NEON.DOC.001113 (1=fail, 0=pass)",
      "__neon_units": "NA"
    }
    ]
}
